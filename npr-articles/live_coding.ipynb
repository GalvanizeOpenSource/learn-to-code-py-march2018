{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Our Data\n",
    "\n",
    "The first step is to read out data into a `pandas` DataFrame.  For an intro to using `pandas` I would highly suggest looking though [this 10 minute guide to `pandas`](http://pandas.pydata.org/pandas-docs/stable/10min.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('npr_articles.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now checkout what our data consists of by using the `.head()` method on our DataFrame.  By default, this will show the top 5 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the first steps you should take is to get an overview of what kind of data we have but running the `.info()` method.  Please [see the documentation](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html) for more info (no pun intended)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the column `date_published` is being interpreted as an `object` and not a datetime.  Let's change that by using the [`pandas.to_datetime()` function](http://pandas.pydata.org/pandas-docs/version/0.19.2/generated/pandas.to_datetime.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date_published'] = pd.to_datetime(df['date_published'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "df['author'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Authors \n",
    "\n",
    "Let's say we wanted to add in another column that contains the number of authors that worked on a particular article.  We could do this like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a mask for all rows that have a non-null value\n",
    "mask = df['author'].notnull()\n",
    "\n",
    "# When the data was saved to a csv, these lists were converted into strings, we can convert\n",
    "# them back like so\n",
    "from ast import literal_eval\n",
    "\n",
    "if type(df['author'][0]) == type('abc'):\n",
    "    df.loc[mask, 'author'] = df.loc[mask, 'author'].map(literal_eval)\n",
    "\n",
    "print(type(df['author'][0]))\n",
    "\n",
    "# Initialize column with NaN's and then fill in the respective values\n",
    "df['num_authors'] = np.nan\n",
    "df.loc[mask, 'num_authors'] = df.loc[mask, 'author'].map(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now take a look at the summary statistics of any numeric columns by running the `.describe()` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Unique Authors\n",
    "\n",
    "Let's say we wanted to get the number of unique authors that are represented in this dataframe.  We could potentially use `df['author'].nunique()` but we are going to run into an error because each row contains a `list` which isn't hashable.\n",
    "\n",
    "Instead we could loop through each value and extend a set like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set to hold our authors\n",
    "authors = set()\n",
    "for lst in df.loc[mask, 'author']:\n",
    "    # For every row, update the authors set with those contained in that row\n",
    "    authors.update(lst)\n",
    "# Print out the total authors seen\n",
    "print(len(authors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we also wanted the number of times a particular author was involved in writing an article we could leverage the power of `Counter`'s from the `collections` library.  Refer to the [documentation](https://docs.python.org/2/library/collections.html) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "authors = df.loc[mask, 'author'].map(Counter).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors['Ari Shapiro']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we wanted to now subset down to the articles which Ari Shapiro worked on.  There are a variety of way's we could do this but I will demo one possible avenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is another way we could acheive this\n",
    "mask = df.loc[df['author'].notnull(), 'author'].map(lambda x: 'Ari Shapiro' in x)\n",
    "\n",
    "df.loc[df['author'].notnull()].loc[mask, 'headline']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most popular sections\n",
    "\n",
    "Let's find what the 5 most popular sections (as judged by the number of articles published within that article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['section'].value_counts(dropna=False)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we first were looking at our DataFrame, you may have noticed that there are quite a few rows missing author information.  Maybe we have a hypothesis that there are certain sections that systemically weren't attaching author information.  Let's dive deeper to try and prove/disprove this hypothesis..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's create a new column that indicates whether the author attribute was null or not\n",
    "# This helps with the groupby below\n",
    "df['author_null'] = df['author'].isnull()\n",
    "\n",
    "# Get the mean amount of nulls for each section and sort descending\n",
    "# NOTE: 1.0 indicates ALL Nulls\n",
    "df.groupby('section')['author_null'].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there are clearly sections that are consistently not attaching author information as well as many that are hit or miss with the author information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Article Count by Time\n",
    "\n",
    "Let's make a plot showing the frequency of articles published by day, week, and month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pandas Series with 1's as the values and the date as the index\n",
    "s = pd.Series([1], index=df['date_published'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we see how we could use the [resample function](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.resample.html) to find the number of articles published per day.  \n",
    "\n",
    "NOTE: Our DataFrame/Series must have a datetimeindex for this to work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's resample that Series and sum the values to find the number of articles by Day\n",
    "s.resample('D').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are, of course, many different offset alias' for passing to `resample`.  For more options [see this page](http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(s.resample('D').sum())\n",
    "plt.title('Article Count By Day')\n",
    "plt.ylabel('Number of Articles')\n",
    "plt.xlabel('Date')\n",
    "locs, labels = plt.xticks()\n",
    "plt.setp(labels, rotation=-45);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(s.resample('W').sum())\n",
    "plt.title('Article Count By Week')\n",
    "plt.ylabel('Number of Articles')\n",
    "plt.xlabel('date')\n",
    "locs, labels = plt.xticks()\n",
    "plt.setp(labels, rotation=-45);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What hour is the most popular time for publishing articles?\n",
    "\n",
    "To answer this let's extract the hour when the article was published and create a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hour_published'] = df['date_published'].dt.hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were able to run the above command because that particular column contains a datetime object.  From there we can run `.dt` and then extract any aspect of that datetime (e.g. `.dt.hour`, `.dt.second`, `.dt.month`, `.dt.quarter`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hour_published'].hist()\n",
    "plt.ylabel('Number of Articles Published')\n",
    "plt.xlabel('Hour Published (24Hr)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the `.hist` method is going to plot 10 bins.  Let's up that to 24 bins so we have a bin for each hour in the day..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's force the plot to split into 24 bins, one for each hour\n",
    "df['hour_published'].hist(bins=24)\n",
    "plt.ylabel('Number of Articles Published')\n",
    "plt.xlabel('Hour Published (24Hr)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's extract the relative frequency rather than the raw counts\n",
    "df['hour_published'].hist(bins=24, normed=True, alpha=0.75)\n",
    "plt.ylabel('Freq. of Articles Published')\n",
    "plt.xlabel('Hour Published (24Hr)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also grab this information without plotting it using .value_counts\n",
    "df['hour_published'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hour_published'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or we could leave them in the order of a day\n",
    "df['hour_published'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Particular Dates\n",
    "\n",
    "Let's select articles which were published between 10 am and 2 pm on December 24th, 2016.  There are a couple of ways we could do this, but let's start by making a mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ((df['date_published'] >= '2016-12-24 10:00:00') &\n",
    "        (df['date_published'] <= '2016-12-24 14:00:00'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[mask, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or we could reset or index and do it that way...\n",
    "df2 = df.set_index('date_published')\n",
    "df2.loc['2016-12-24 10:00:00': '2016-12-24 14:00:00', :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Length of Articles (# Words)\n",
    "\n",
    "Maybe we are interested in looking at the distribution of how long our articles are..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_words'] = df['article_text'].map(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_words'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a histogram of the length of different articles..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_words'].hist(bins=20, alpha=0.75)\n",
    "plt.ylabel('Number of Articles Published')\n",
    "plt.xlabel('Length of Article');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly there are some outliers in this data.  Let's subset what we are plotting to cut out the top 2% of articles in terms of article length and see what the resulting histogram looks like...\n",
    "\n",
    "Refer to [the `numpy` percentile function](https://docs.scipy.org/doc/numpy-dev/reference/generated/numpy.percentile.html) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = np.percentile(df['num_words'], 98)\n",
    "\n",
    "df.loc[df['num_words'] <= cutoff, 'num_words'].hist(bins=20, alpha=0.75)\n",
    "plt.ylabel('Number of Articles Published')\n",
    "plt.xlabel('Length of Article');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only rows that contain 'Obama' in the Headline\n",
    "\n",
    "We can also use standard string functions by using the `.str` functionality in `pandas`.  Take a look at [this page](http://pandas.pydata.org/pandas-docs/stable/text.html) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['headline'].str.contains('Obama'), 'headline'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at Average Hour Published by Section\n",
    "\n",
    "Maybe we have a hypothesis that different sections will vary in the time of day that they are publishing.  We could try and get a sense for this like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's subset to just the 10 most popular sections\n",
    "top_sections = df['section'].value_counts()[:10].index\n",
    "df_sub = df.loc[df['section'].isin(top_sections), :]\n",
    "\n",
    "# We are now grouping by the section and extracting the mean hour that articles were published\n",
    "df_sub.groupby('section')['hour_published'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
